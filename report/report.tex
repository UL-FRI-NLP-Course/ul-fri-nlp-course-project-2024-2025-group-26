%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% FRI Data Science_report LaTeX Template
% Version 1.0 (28/1/2020)
% 
% Jure Demšar (jure.demsar@fri.uni-lj.si)
%
% Based on MicromouseSymp article template by:
% Mathias Legrand (legrand.mathias@gmail.com) 
% With extensive modifications by:
% Antonio Valente (antonio.luis.valente@gmail.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------
\documentclass[fleqn,moreauthors,10pt]{ds_report}
\usepackage[english]{babel}

\graphicspath{{fig/}}




%----------------------------------------------------------------------------------------
%	ARTICLE INFORMATION
%----------------------------------------------------------------------------------------

% Header
\JournalInfo{FRI Natural language processing course 2025}

% Interim or final report
\Archive{Project report} 
%\Archive{Final report} 

% Article title
\PaperTitle{Automatic generation of Slovenian traffic news for RTV Slovenija} 

% Authors (student competitors) and their info
\Authors{Janez Kuhar, Veljko Dudić, and Marko Rozman}

% Advisors
\affiliation{\textit{Advisors: Slavko Žitnik}}

% Keywords
\Keywords{}
\newcommand{\keywordname}{Keywords}


%----------------------------------------------------------------------------------------
%	ABSTRACT
%----------------------------------------------------------------------------------------

\Abstract{
In this report we present the related works, initial ideas and proposed dataset for our project.
}

%----------------------------------------------------------------------------------------

\begin{document}

% Makes all text pages the same height
\flushbottom 

% Print the title and abstract box
\maketitle 

% Removes page numbering from the first page
\thispagestyle{empty} 

%----------------------------------------------------------------------------------------
%	ARTICLE CONTENTS
%----------------------------------------------------------------------------------------

\section*{Introduction}
The project focuses on replacing the manual production of traffic reports with an automated system. Traffic data provided in tabular form and traffic data from the promet.si website is used to generate traffic reports according to provided specifications.

\subsection*{Motivation}

\textbf{Timely Information.} Reliable traffic updates are critical for public safety and efficient transportation management.\\
\textbf{Manual Process Limitations.} Currently, students manually verify and type these reports every 30 minutes, leading to potential delays and inaccuracies.\\
\textbf{Automated Solution.} By utilizing LLMs and advanced prompt engineering (inspired by works on news headline generation), we aim to generate clear, concise, and contextually accurate traffic news.

\section{Related Work}

Li et al. \cite{liHGNewsNewsHeadline2021} proposed a decoder-only model for headline generation,
incorporating multihead attention, sentiment features, and part-of-speech information. Its focus
on generating succinct news headlines while accurately handling out-of-vocabulary
terms (such as specific road names) can be directly applicable to our task.

In a more recent work on the topic of text summarization \cite{houAlgorithmAutomaticAbstract2024}, a ChatGPT-based
algorithm for summarizing Russian texts was proposed. The suggested approach combined preprocessing (e.g., word segmentation,
stop word removal) with BERT for contextual understanding and a pointer mechanism for out-of-vocabulary
words.

Sha et al. \cite{sha2018order} proposed an order-planning mechanism for text generation from tabular data, combining
link-based attention with traditional content-based attention to model the sequence of information. Their approach
was further enhanced by a copy mechanism to handle rare words, improving the model's ability to generate accurate
and coherent summaries from structured data.

\section{Initial ideas}
\begin{itemize}
    \item Initial Prompt Engineering: Experiments will start by generating news texts directly from the structured traffic data using prompts.
    
    \item Selection of important data. Our observations show that the final news report is mostly made from only few important data points from the Excel file. We intend to filter the data to remove duplicate enteries and automaticly select the important data points relavant for our traffic news generation.
    
    \item Enhanced Generation through Fine-Tuning: The project will then incorporate parameter-efficient fine-tuning (e.g., LoRA) and retrieval techniques to further refine the generated content, ensuring correct road naming and event descriptions.
    
    \item Evaluation: A robust evaluation framework will be established using both automatic metrics (such as ROUGE, precision, recall, and F1) and human judgment to verify that the generated texts meet RTV Slovenija's standards.

    \item Pointer Mechanisms: Integrate pointer mechanisms to ensure that domain-specific terminology (e.g., road names and traffic event descriptors) is accurately reproduced, minimizing the risk of omitting critical details.

    \item Advanced Preprocessing: Apply rigorous preprocessing techniques—such as tokenization, normalization, and filtering—to both the traffic data and guideline documents. This will help standardize the input and ensure adherence to established formats.

    \item N-gram Language Features: Incorporate n-gram features to improve language fluency and ensure that generated sentences are coherent and stylistically consistent with existing RTV Slovenija news.

    \end{itemize}

\section{Methods}

\subsection*{Project dataset}

The primary dataset was provided to us by the TA. It consists of three important sets of files:

\begin{enumerate}
    \item \textbf{A structured Excel }file containing historical traffic report information from \textit{promet.si}.
    \item \textbf{Word documents} with lexical notes and the prescribed structure of a traffic report.
    \item \textbf{Ground truth data} in Rich Text Format (RTF) files, providing text in a ready-to-use format for radio hosts.
\end{enumerate}


\subsection*{Data preprocessing}
The pipeline first loads the RTF files and extracts dates and times embedded in their content. It then selects the corresponding rows from the Excel file based on this timestamp information. From these selected rows, duplicate entries are removed, and the HTML content present in the columns is converted into plain text. The process further cleans the data by keeping only the relevant columns (namely A1, B1, C1, A2, B2, C2, ContentPomembnoSLO, ContentNesreceSLO, ContentZastojiSLO, ContentVremeSLO, ContentOvireSLO, ContentDeloNaCestiSLO, ContentOpozorilaSLO, ContentMednarodneInformacijeSLO, and ContentSplosnoSLO), which are then merged to form the input text for the model.


\subsection*{Prompt Engineering}

After preprocessing the tabular data, we employed a simple prompt engineering approach to generate the traffic news.
We started with a \textit{few-shot} prompting \cite{promptingguide_fewshot} technique, where we provided the model
with a few examples of preprocessed data and corresponding traffic news reports. This approach provides the model
with contextual examples, helping it mimic the structure and tone of the target traffic news format.

\subsection*{Evaluation metrics}

The evaluation focuses on the BLEU score as a measure of translation quality, with the possibility of adding other metrics in the future.

\noindent \textbf{BLEU Score:} The BLEU (Bilingual Evaluation Understudy) score is a popular metric for evaluating the quality of machine-generated text, particularly for tasks like text summarization or machine translation. It is based on precision, specifically n-gram precision, where a higher BLEU score indicates that the machine-generated text closely matches the ground truth.

The BLEU score ranges from 0 to 1, where a higher value suggests better quality. However, BLEU has limitations, especially when dealing with languages that have more varied sentence structures or when evaluating more creative text generation tasks like traffic report creation. For example, it does not account for semantic meaning and may penalize diverse word choices or paraphrasing that is still correct. Additionally, BLEU heavily relies on n-gram matching, which may penalize acceptable lexical variations. For example, if the model uses different phrasing that still conveys the same meaning, it may receive a lower BLEU score, which does not necessarily reflect a poor-quality output.


\section{Results and Evaluation}

\subsection*{Computational Resources}

Inference for all experiments was conducted on the ARNES High-Performance Computing (HPC) cluster, which provides robust resources for large-scale machine learning tasks. The cluster is equipped with NVIDIA H100 GPUs, each featuring 80GB of memory, enabling efficient handling of large language models.

\subsection*{Quantitative Results}

For each experimental setup, we ran 32 trials to ensure statistical reliability. During each trial, a randomly sampled
set of input-output pairs was used, and the performance score was calculated for each pair.


The baseline results for few-shot prompting with GaMS-9B-Instruct \cite{huggingface2025gams9b} are listed in Table~\ref{tab:bleu-results}. We experimented with different configurations by varying the number of shots (input/output pairs) and the number of rows merged from the Excel file into a single input.
\begin{table}[h!]
    \centering
    \caption{Average BLEU scores for different few-shot prompting setups using GaMS-9B-Instruct. Each configuration was evaluated over 32 trials. \textbf{Rows}: The number of Excel rows merged into a single input. \textbf{Shots}: The number of input/output pairs presented to the model for few-shot prompting.}
    \label{tab:bleu-results}
    \small
    \begin{tabular}{@{}cccc@{}}
    \toprule
    \textbf{Rows} & \textbf{Shots} & \textbf{Trials} & \textbf{BLEU} \\
    \midrule
    1 & 8 & 32 & \textbf{0.1942} \\
    3 & 2 & 32 & \textbf{0.1576} \\
    \bottomrule
    \end{tabular}
\end{table}

As expected, increasing the number of shots provided the model with more context, which typically improves its performance. However, increasing the number of shots also resulted in higher memory consumption, so we had to find a balance that remained within our system's limits.

Interestingly, the average BLEU score decreased when we merged several Excel rows into the input. While we expected more data to improve the model's performance, the increase in data duplication led us to reduce the number of shots. With only 2 examples presented to the model, the model lacked sufficient context to recover all the relevant details from the ground truth, which likely led to missing parts in the generated reports.
    

%----------------------------------------------------------------------------------------
%	REFERENCE LIST
%----------------------------------------------------------------------------------------
\bibliographystyle{unsrt}
\bibliography{report}


\end{document}
